{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Final Project Submission\n",
    "\n",
    "***\n",
    "- Student Name: Adam Marianacci\n",
    "- Student Pace: Flex\n",
    "- Scheduled project review date/time: TBD\n",
    "- Instructor Name: Mark Barbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is my job to help SXSW detect positive sentiment from tweets about their event so that they can continue to give people what they want and make improvements for the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from 'CrowdFlower' via data.world. The initial dataframe contained roughly 9,000 tweets and information about the sentiment of the tweet as well as what brand or product the tweet was directed at. Some limitations of the dataset included missing values as well as a class imbalance in the sentiment of the tweets. Over 50% of the tweets showed no emotion, about 33% showed a positive emotion, and only around 6% showed a negative emotion. Due to this imbalance I combined some of the 'no emotion' tweets with the 'negative emotion' tweets to create a 'Not Positive' class to match the 'Positive' class. There was a lot of missing data from the emotion about the brands so I was unable to conduct analysis in this area. This dataset was suitable for the project because it allowed me to build a sentiment detection model from the text in the tweets against the target 'sentiment' of what was positive and what was not.\n",
    "\n",
    "\n",
    "Dataset: [Brands and Product Emotions](https://data.world/crowdflower/brands-and-product-emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data, and looking at the shape of the df\n",
    "\n",
    "corpus = pd.read_csv('data/twitter_sentiment.csv', encoding='latin1')\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing the dataframe\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Taking a look at the datatypes and checking for missing values\n",
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'the emotion_in_tweet_is_directed_at' column, bc of missing values and not needed for our problem.\n",
    "corpus.drop('emotion_in_tweet_is_directed_at', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the 'is_there_an_emotion...' column to 'sentiment'\n",
    "corpus.rename(columns={\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the values in 'sentiment'. We have an imbalance in occurences. \n",
    "corpus['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'I can't tell' category because it is not useful and a relatively low amount.\n",
    "corpus.drop(corpus[corpus['sentiment'] == \"I can't tell\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emotion toward brand or product    2981\n",
      "Positive emotion                      2978\n",
      "Negative emotion                      2978\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a mask to identify rows with \"No emotion toward brand or product\"\n",
    "no_emotion_mask = corpus['sentiment'] == \"No emotion toward brand or product\"\n",
    "\n",
    "# Locating the rows with the mask and redistribute 2,408 occurrences\n",
    "no_emotion_indices = corpus[no_emotion_mask].sample(n=2408, random_state=42).index\n",
    "corpus.loc[no_emotion_indices, 'sentiment'] = \"Negative emotion\"\n",
    "\n",
    "# Verifying the changes\n",
    "print(corpus['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive emotion    2978\n",
      "Negative emotion    2978\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify rows with \"No emotion toward brand or product\"\n",
    "no_emotion_mask = corpus['sentiment'] == \"No emotion toward brand or product\"\n",
    "\n",
    "# Drop the rows with this mask\n",
    "corpus.drop(corpus[no_emotion_mask].index, inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(corpus['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Positive    2978\n",
      "Positive        2978\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping of old values to new values\n",
    "mapping = {'Positive emotion': 'Positive', 'Negative emotion': 'Not Positive'}\n",
    "\n",
    "# Replace the categories in the 'sentiment' column\n",
    "corpus['sentiment'] = corpus['sentiment'].replace(mapping)\n",
    "\n",
    "# Verify the changes\n",
    "print(corpus['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 'Positive' sentiment to 1 and 'Not Positive' to 0\n",
    "corpus['sentiment'] = corpus['sentiment'].replace(\n",
    "    {'Positive': 1, 'Not Positive': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cells 9-12 we have set this up to be a binary classification problem. We have combined values from \"Negative emotion\" with values from \"No emotion toward brand or product\". We did this because we had a class imbalance. We sampled 2,408 occurences from \"No emotion toward brand or product\" and combined them in the \"Negative emotion\" category to create a new category called \"Not Positive\". There were a lot more occurences of \"Positive emotion\" compared to \"Negative emotion\". By combining the categories we have now have a balance between 'Positive' and 'Not Positive' occurences. We have assigned sentiment values 'Positive' to 1 and 'Not Positive' to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5956 entries, 0 to 9092\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  5956 non-null   object\n",
      " 1   sentiment   5956 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 139.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the DF once again to make sure everything looks correct after all the changes we made.\n",
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  5956.000000\n",
       "mean      0.500000\n",
       "std       0.500042\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of entries are equal in 'tweet_text' and 'sentiment'\n",
    "corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...          0\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...          1\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...          1\n",
       "3  @sxsw I hope this year's festival isn't as cra...          0\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting common words that have low semantic value that could potentially be added to 'stopwords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mention: 4211\n",
      "the: 2671\n",
      "#sxsw: 2602\n",
      "{link}: 2579\n",
      "#SXSW: 2384\n",
      "to: 2328\n",
      "RT: 1851\n",
      "at: 1848\n",
      "for: 1594\n",
      "a: 1484\n",
      "iPad: 1206\n",
      "in: 1181\n",
      "of: 1151\n",
      "is: 1141\n",
      "and: 1022\n",
      "Google: 994\n",
      "Apple: 991\n",
      "on: 817\n",
      "I: 724\n",
      "store: 618\n"
     ]
    }
   ],
   "source": [
    "# Finding the top 10 most used words in the tweets\n",
    "all_words = ' '.join(corpus['tweet_text']).split()\n",
    "\n",
    "# Calculate the frequency distribution of words\n",
    "word_freq = FreqDist(all_words)\n",
    "\n",
    "# Get the top 10 most frequent words\n",
    "top_20_words = word_freq.most_common(20)\n",
    "\n",
    "# Print the top 10 most frequent words\n",
    "for word, freq in top_20_words:\n",
    "    print(f'{word}: {freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = corpus.tweet_text\n",
    "y = corpus.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is our holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up train,test,split, 20% on testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in stopwords, words with low semantic value\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "# add additional words to the stopwords list\n",
    "additional_stopwords = ['sxsw', 'apple', 'google', 'austin', 'ipad', \n",
    "                        'iphone', 'mention', 'android', 'rt', 'link',\n",
    "                       'app', 'quot', 'store', 'aaron', 'abc', 'aapl',\n",
    "                       'ab']\n",
    "sw.extend(additional_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating nltk pos_tags to wordnet pos_tags to ensure compatability between libraries\n",
    "# Preparing for lemmatization\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation, lower casing, removing numbers, lemmatizing the tweets\n",
    "def tweet_preparer(tweet, stop_words=sw, ):\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    tweet = regex_token.tokenize(tweet)\n",
    "    tweet = [word.lower() for word in tweet]\n",
    "    tweet = [word for word in tweet if word not in sw]\n",
    "    # print(tweet)\n",
    "    tweet = pos_tag(tweet)\n",
    "    tweet = [(word[0], get_wordnet_pos(word[1])) for word in tweet]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tweet = [lemmatizer.lemmatize(word[0], word[1]) for word in tweet]\n",
    "    return ' '.join(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mention  Its bigger than an iphone and smaller than a PC, so good for big events like #SXSW and meeting day? {link}\n",
      "big small pc good big event like meeting day\n"
     ]
    }
   ],
   "source": [
    "# Select a sample tweet from the corpus DataFrame\n",
    "sample_tweet = corpus['tweet_text'].iloc[522]  #'tweet_text' is the column containing the tweets\n",
    "print(sample_tweet)\n",
    "# Apply tweet_preparer function to preprocess the sample tweet\n",
    "preprocessed_tweet = tweet_preparer(sample_tweet)\n",
    "print(preprocessed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variable 'token_tweets' to preprocess all the tweets in the corpus using a list comprehension.\n",
    "token_tweets = [tweet_preparer(tweet, sw) for tweet in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary train-test split to build our baseline model\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(token_tweets, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train2_vec = cv.fit_transform(X_train2)\n",
    "X_train2_vec = pd.DataFrame.sparse.from_spmatrix(X_train2_vec)\n",
    "X_train2_vec.columns = sorted(cv.vocabulary_)\n",
    "X_train2_vec.set_index(y_train2.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in 'X_train2_vec': 3811\n",
      "Number of columns in 'X_train2_vec': 5148\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the 'X_train2_vec' sparse matrix\n",
    "num_rows, num_columns = X_train2_vec.shape\n",
    "\n",
    "print(\"Number of rows in 'X_train2_vec':\", num_rows)\n",
    "print(\"Number of columns in 'X_train2_vec':\", num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abt</th>\n",
       "      <th>abuzz</th>\n",
       "      <th>acc</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zite</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3811 rows × 5148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  abound  abroad  absolutely  absolutley  abt  abuzz  acc  \\\n",
       "7286        0     0       0       0           0           0    0      0    0   \n",
       "6929        0     0       0       0           0           0    0      0    0   \n",
       "968         0     0       0       0           0           0    0      0    0   \n",
       "2538        0     0       0       0           0           0    0      0    0   \n",
       "6473        0     0       0       0           0           0    0      0    0   \n",
       "...       ...   ...     ...     ...         ...         ...  ...    ...  ...   \n",
       "3853        0     0       0       0           0           0    0      0    0   \n",
       "4179        0     0       0       0           0           0    0      0    0   \n",
       "5569        0     0       0       0           0           0    0      0    0   \n",
       "4053        0     1       0       0           0           0    0      0    0   \n",
       "427         0     0       0       0           0           0    0      0    0   \n",
       "\n",
       "      access  ...  zip  zite  zlf  zms  zomb  zombie  zomg  zone  zoom  zynga  \n",
       "7286       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6929       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "968        0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "2538       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6473       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "...      ...  ...  ...   ...  ...  ...   ...     ...   ...   ...   ...    ...  \n",
       "3853       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "4179       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5569       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "4053       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "427        0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "\n",
       "[3811 rows x 5148 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abt</th>\n",
       "      <th>abuzz</th>\n",
       "      <th>acc</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zite</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3811 rows × 5148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  abound  abroad  absolutely  absolutley  abt  abuzz  acc  \\\n",
       "7286        0     0       0       0           0           0    0      0    0   \n",
       "6929        0     0       0       0           0           0    0      0    0   \n",
       "968         0     0       0       0           0           0    0      0    0   \n",
       "2538        0     0       0       0           0           0    0      0    0   \n",
       "6473        0     0       0       0           0           0    0      0    0   \n",
       "...       ...   ...     ...     ...         ...         ...  ...    ...  ...   \n",
       "3853        0     0       0       0           0           0    0      0    0   \n",
       "4179        0     0       0       0           0           0    0      0    0   \n",
       "5569        0     0       0       0           0           0    0      0    0   \n",
       "4053        0     1       0       0           0           0    0      0    0   \n",
       "427         0     0       0       0           0           0    0      0    0   \n",
       "\n",
       "      access  ...  zip  zite  zlf  zms  zomb  zombie  zomg  zone  zoom  zynga  \n",
       "7286       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6929       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "968        0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "2538       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6473       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "...      ...  ...  ...   ...  ...  ...   ...     ...   ...   ...   ...    ...  \n",
       "3853       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "4179       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5569       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "4053       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "427        0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "\n",
       "[3811 rows x 5148 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then transform the validation set. Do not refit the vectorizer\n",
    "\n",
    "X_val_vec = cv.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abt</th>\n",
       "      <th>abuzz</th>\n",
       "      <th>acc</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zite</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 5148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  abound  abroad  absolutely  absolutley  abt  abuzz  acc  \\\n",
       "3342        0     1       0       0           0           0    0      0    0   \n",
       "5195        0     0       0       0           0           0    0      0    0   \n",
       "5284        0     0       0       0           0           0    0      0    0   \n",
       "2154        0     0       0       0           0           0    0      0    0   \n",
       "6817        0     0       0       0           0           0    0      0    0   \n",
       "...       ...   ...     ...     ...         ...         ...  ...    ...  ...   \n",
       "7416        0     0       0       0           0           0    0      0    0   \n",
       "6770        0     0       0       0           0           0    0      0    0   \n",
       "5110        0     0       0       0           0           0    0      0    0   \n",
       "5522        0     0       0       0           0           0    0      0    0   \n",
       "2038        0     0       0       0           0           0    0      0    0   \n",
       "\n",
       "      access  ...  zip  zite  zlf  zms  zomb  zombie  zomg  zone  zoom  zynga  \n",
       "3342       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5195       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5284       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "2154       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6817       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "...      ...  ...  ...   ...  ...  ...   ...     ...   ...   ...   ...    ...  \n",
       "7416       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "6770       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5110       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "5522       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "2038       0  ...    0     0    0    0     0       0     0     0     0      0  \n",
       "\n",
       "[953 rows x 5148 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Multinomial Naive Bayes Classifier on our training data\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_train2_vec, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8509577538703752"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating our training data\n",
    "y_train_pred = mnb.predict(X_train2_vec)\n",
    "accuracy_score(y_train2, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.646379853095488"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating model predictions and getting an accuracy score for our Testing Data\n",
    "y_pred = mnb.predict(X_val_vec)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408839779005525"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating a precision score\n",
    "precision_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an 85% accuracy score on our training data and roughly a 65% accuracy score on our testing data. We had a similar score of 64% on precision. Our model did do significantly better on the training data most likely due to overfitting from noise in the training data (too many irrelevant words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6473373167803566\n",
      "Best Parameters: {'alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],              # alpha parameter for MultinomialNB\n",
    "}\n",
    "\n",
    "# Initialize MultinomialNB classifier\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Perform GridSearchCV with accuracy as the scoring metric with 5 folds\n",
    "grid_search = GridSearchCV(mnb, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Training the GridSearchCV on the training data\n",
    "grid_search.fit(X_train2_vec, y_train2)\n",
    "\n",
    "# Geting the best accuracy score and hyperparameters\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch mnb model led to an ever so slight improvement, but roughly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a confusion matrix on our testing data\n",
    "cm = confusion_matrix(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a figure and axis\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)  # Adjust font size for better readability\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
    "            annot_kws={\"size\": 14}, square=True,\n",
    "            xticklabels=['Not Positive', 'Positive'],\n",
    "            yticklabels=['Not Positive', 'Positive'])\n",
    "\n",
    "# Labeling and viewing the cm\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4963273871983211"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a tfidf model on training data to make predictions with words that appear in 5%-95% of tweets\n",
    "tfidf = TfidfVectorizer(min_df=0.05, max_df=0.95)\n",
    "X_train2_vec = tfidf.fit_transform(X_train2)\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "mnb2 = MultinomialNB()\n",
    "mnb2.fit(X_train2_vec, y_train2)\n",
    "y_pred2 = mnb2.predict(X_val_vec)\n",
    "\n",
    "accuracy_score(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201612903225806"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tfidf mnb model with min, max hyperparameters led to a worse accuracy score of almost 50%, and had a worse precision score as well at 52%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5210396039603961"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a Random Forest Classifier on training data, and making predictions on validation data\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features=5, max_depth=5)\n",
    "rf.fit(X_train2_vec, y_train2)\n",
    "y_pred3 = rf.predict(X_val_vec)\n",
    "precision_score(y_val, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521511017838405"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model with hyperparameters did not perform as well as the mnb model. This model had an accuracy score of 52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important words:\n",
      "acc: 0.249670\n",
      "abound: 0.190295\n",
      "able: 0.141614\n",
      "ability: 0.136165\n",
      "absolutley: 0.092315\n",
      "abroad: 0.053316\n",
      "absolutely: 0.047517\n",
      "access: 0.041522\n",
      "abuzz: 0.036644\n",
      "abt: 0.010943\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained Random Forest classifier\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Get the indices of the top 10 most important features\n",
    "top_feature_indices = feature_importances.argsort()[-10:][::-1]\n",
    "\n",
    "# Get the vocabulary from the CountVectorizer\n",
    "vocab = cv.get_feature_names_out()\n",
    "\n",
    "# Print the top 10 most important words\n",
    "print(\"Top 10 most important words:\")\n",
    "for index in top_feature_indices:\n",
    "    word = vocab[index]\n",
    "    importance = feature_importances[index]\n",
    "    print(f\"{word}: {importance:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing model was our Multinomial Bayes model that used a GridSearch with hyperparameters, the alpha was set to 1. This is an example of Laplace smoothing which avoids the problem of zero probabilities of unseen words in the training data. The model was trained on data using a count vectorizer of all the words in the corpus after preprocessing. It had an accuracy score of about 65% which is not great in determining whether tweets had positive sentiment or not. It also had a precision score that was roughly the same. We looked at accuracy as the best metric because in terms of minimizing false/negatives and false/positives, one was not more important than the other. Therefore precision and recall didn't matter as much as accuracy. It was a better metric because we had a balance in our classes. Our confusion matrix confirmed this by showing we had 616 True Predictions out of 953 possible in our sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some limitations of the data was that there was a pretty heavy class imbalance in sentiment. Over half of the data (in this case tweets) showed to have no emotion. With only 33% showing positive sentiment and only around 6% showing negative sentiment. This forced us to combine no emotion tweets and negative tweets to create a 'Not Positive' category. This contributed to our models not being very accurrate. There were also a lot of missing values (nearly 2/3) of the data was missing from the 'emotion_in_tweet_is_directed_at' column so I was not able to analyze sentiment regarding certain products. After cleaning the data we were only able to work with around 6,000 entries which is fairly low when it comes to building predictive models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to gather more data on negative sentiment as well as positive sentiment. Negative sentiment is just as useful and in some cases more useful information to have to know what to avoid and how to make improvements. We need to gather 10x more data from other social media platforms as well, not just twitter. Gathering information on specific areas of the conference (whether it be in film, music, education or brands in tech) will help SXSW become an even better more well rounded event rather than just looking at general sentiment towards the event. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
